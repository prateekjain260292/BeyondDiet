{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\RUTGERS\\\\Analytics\\\\BDdata_S1_prateek5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd6d5d52e91b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlist1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\RUTGERS\\Analytics\\BDdata_S1_prateek5.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mele\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\RUTGERS\\\\Analytics\\\\BDdata_S1_prateek5.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#0,2,6,7,9,14,15,16,17,18\n",
    "list = []\n",
    "list1 = []\n",
    "with open('C:\\RUTGERS\\Analytics\\BDdata_S1_prateek5.csv') as f:\n",
    "    for line in f:\n",
    "        ele = line.split(',')\n",
    "        #list.append(line.split(','))\n",
    "        list.append(np.delete(line.split(','), [0,1,2,5,10,12]).tolist())\n",
    "\n",
    "\"\"\"\n",
    "count = 0\n",
    "print (list[0])\n",
    "del list[0]\n",
    "for ele in list:\n",
    "    if float(ele[8]) == float(ele[9]):\n",
    "        count = count+1\n",
    "print (count)\n",
    "\"\"\"\n",
    "print (list[0])\n",
    "print (list[1])\n",
    "print (list[2])\n",
    "print (list[25645])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_train = []\n",
    "for ele in list:\n",
    "    if ele[7] == 'repeatPurchaser\\n':\n",
    "        class_train.append(0)\n",
    "    else:\n",
    "        class_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = ['F','M','NULL']\n",
    "MonthJoined = ['January','February','March','April','May','June','July','August','September','October', 'NULL']\n",
    "\n",
    "source = ['facebook', 'NULL', 'HumanInteraction', 'bing', 'adwords', 'pinterest', 'retargeting', 'affiliate', 'google', 'youtube', 'thrivefacebook']\n",
    "device = ['iphone', 'NULL', 'anphone', 'desktop']\n",
    "\n",
    "final = []\n",
    "\n",
    "for ele in list:\n",
    "    gen = ele[0]\n",
    "    mon = ele[2]\n",
    "    sou = ele[3]\n",
    "    dev = ele[4]\n",
    "    if ele[1] == 'NULL':\n",
    "        age = 7\n",
    "    elif float(ele[1]) <= 17:\n",
    "        age = 0\n",
    "    elif float(ele[1]) <= 24:\n",
    "        age = 1\n",
    "    elif float(ele[1]) <= 34:\n",
    "        age = 2\n",
    "    elif float(ele[1]) <= 44:\n",
    "        age = 3\n",
    "    elif float(ele[1]) <= 54:\n",
    "        age = 4\n",
    "    elif float(ele[1]) <= 64:\n",
    "        age = 5\n",
    "    else:\n",
    "        age = 6\n",
    "    if ele[1] == 'NULL':\n",
    "        ele[1] = 0\n",
    "    if ele[5] == 'NULL':\n",
    "        ele[5] = 0\n",
    "    if ele[6] == 'NULL':\n",
    "        ele[6] = 0\n",
    "    final.append([gender.index(gen), float(ele[1]), MonthJoined.index(mon), source.index(sou), device.index(dev), float(ele[5]), float(ele[6])])\n",
    "    #final.append([gender.index(gen), MonthJoined.index(mon), source.index(sou), device.index(dev), float(ele[6])])\n",
    "    #final.append([gender.index(gen), age, MonthJoined.index(mon), source.index(sou), device.index(dev), float(ele[5]), float(ele[6])])\n",
    "\n",
    "    \n",
    "print (list[0])\n",
    "print (list[1])\n",
    "print (final[0])\n",
    "print (final[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final, class_train, test_size=0.2, random_state=0)\n",
    "\n",
    "c = Counter(y_train)\n",
    "print (c.most_common())\n",
    "\n",
    "c = Counter(y_test)\n",
    "print (c.most_common())\n",
    "\n",
    "\n",
    "print (len(y_train))\n",
    "print (len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "class_names = ['Multiple','Once']\n",
    "#print len(X_train)\n",
    "#print len(y_train)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, final, class_train, cv=10, scoring = 'f1_weighted')\n",
    "\n",
    "print(scores)\n",
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "class_names = ['Multiple','Once']\n",
    "#print len(X_train)\n",
    "#print len(y_train)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(np.array(X_test))\n",
    "proba = clf.predict_proba(np.array(X_test))\n",
    "\n",
    "score = []\n",
    "for ele in proba:\n",
    "    score.append(ele[1])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy: '+str(accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred, target_names=class_names))\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_features = None)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "pred2 = clf2.predict(np.array(X_test))\n",
    "proba2 = clf2.predict_proba(np.array(X_test))\n",
    "tree = clf2.decision_path(X_test)\n",
    "print (clf2.feature_importances_)\n",
    "\n",
    "print (tree)\n",
    "\n",
    "score2 = []\n",
    "for ele in proba2:\n",
    "    score2.append(ele[1])\n",
    "\n",
    "\n",
    "print ('Accuracy: '+str(accuracy_score(y_test, pred2)))\n",
    "print(classification_report(y_test, pred2, target_names=class_names))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, pred2)\n",
    "\n",
    "%matplotlib inline\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "pred3 = clf3.predict(np.array(X_test))\n",
    "proba3 = clf3.predict_proba(np.array(X_test))\n",
    "\n",
    "score3 = []\n",
    "for ele in proba3:\n",
    "    score3.append(ele[1])\n",
    "\n",
    "print ('Accuracy: '+str(accuracy_score(y_test, pred3)))\n",
    "print(classification_report(y_test, pred3, target_names=class_names))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, pred3)\n",
    "\n",
    "%matplotlib inline\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.figure()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score)\n",
    "plt.plot(fpr,tpr,color='b', alpha=0.2, label= 'Naive')\n",
    "\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_test, score2)\n",
    "plt.plot(fpr2,tpr2,color='r', alpha=0.2, label= 'RF')\n",
    "\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y_test, score3)\n",
    "plt.plot(fpr3,tpr3,color='g', alpha=0.2, label= 'SVC')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
